{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Task 1: classify the data using linear regression, SVM (feel free to play with kernel options), and kNN algorithms; provide accuracy and precision data for each. Suggest reasoning as to why the ones performing better might do so (you do not have to be correct – for this project, this is just something you should enjoy considering).\n"
      ],
      "metadata": {
        "id": "skxz67GFaeHY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Approach 1:**"
      ],
      "metadata": {
        "id": "PyZtufHsalXL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qa4ccFOCaaKZ",
        "outputId": "c2efc2cb-a51e-425a-c395-34e1885bd252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file downloaded successfully as 'EEG data - Sheet1.csv'\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "# URL of the published Google Sheets CSV file\n",
        "url = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vSC87hYugbdg0_MbAhqVHaGSTk_-tEb_X_1YeXo6qzuz-bKm3Vo3gQd6m4IlZ5CAQMUUxfZrtCgbWYv/pub?output=csv\"\n",
        "\n",
        "# Download the CSV file\n",
        "response = requests.get(url)\n",
        "\n",
        "# Save the file locally\n",
        "if response.status_code == 200:\n",
        "    with open(\"EEG data - Sheet1.csv\", \"wb\") as file:\n",
        "        file.write(response.content)\n",
        "    print(\"CSV file downloaded successfully as 'EEG data - Sheet1.csv'\")\n",
        "else:\n",
        "    print(\"Failed to download CSV file. Status code:\", response.status_code)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from scipy.stats import uniform\n",
        "from sklearn.utils import resample\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "np.random.seed(42)\n",
        "file_path = \"EEG data - Sheet1.csv\""
      ],
      "metadata": {
        "id": "lh028XQoau2y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(file_path)\n",
        "df = df.drop(columns=['Unnamed: 0'])\n",
        "\n",
        "X = df.drop(columns=['target'])\n",
        "y = df['target']\n",
        "\n",
        "# Data Augmentation: Generate synthetic samples with noise\n",
        "num_synthetic_samples = 120\n",
        "noise_factor = 0.5\n",
        "synthetic_X = X.sample(n=num_synthetic_samples, replace=True, random_state=42).values\n",
        "synthetic_y = y.sample(n=num_synthetic_samples, replace=True, random_state=42).values\n",
        "synthetic_X += noise_factor * np.random.randn(*synthetic_X.shape)\n",
        "\n",
        "X_augmented = np.vstack((X.values, synthetic_X))\n",
        "y_augmented = np.hstack((y.values, synthetic_y))\n",
        "scaler = StandardScaler()\n",
        "X_augmented = scaler.fit_transform(X_augmented)\n",
        "\n",
        "# Apply PCA (reduce to 40 principal components)\n",
        "pca = PCA(n_components=40)\n",
        "X_pca = pca.fit_transform(X_augmented)\n",
        "\n",
        "# Select best 10 features using SelectKBest\n",
        "selector = SelectKBest(f_classif, k=10)\n",
        "X_selected = selector.fit_transform(X_pca, y_augmented)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y_augmented, test_size=0.2, random_state=42)\n",
        "\n",
        "# Classifiers\n",
        "models = {\n",
        "    \"Linear Regression (SGDClassifier)\": SGDClassifier(loss='log_loss', max_iter=1000),\n",
        "    \"SVM (RBF Kernel)\": SVC(kernel='rbf'),\n",
        "    \"kNN (k=5)\": KNeighborsClassifier(n_neighbors=5)\n",
        "}\n",
        "\n",
        "# Train and evaluate models\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    results[name] = (accuracy, precision)\n",
        "\n",
        "# Print model results\n",
        "print(\"Model Performance:\")\n",
        "for name, (acc, prec) in results.items():\n",
        "    print(f\"{name}: Accuracy = {acc:.2f}, Precision = {prec:.2f}\")\n",
        "\n",
        "#Applying Gridsearch for svm, knn\n",
        "# Define hyperparameter grid for SVM\n",
        "svm_param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "# Define hyperparameter grid for KNN\n",
        "knn_param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
        "}\n",
        "\n",
        "# Initialize models\n",
        "svm_model = SVC()\n",
        "knn_model = KNeighborsClassifier()\n",
        "\n",
        "# Run GridSearchCV for SVM\n",
        "svm_grid_search = GridSearchCV(svm_model, svm_param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
        "svm_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Run GridSearchCV for KNN\n",
        "knn_grid_search = GridSearchCV(knn_model, knn_param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
        "knn_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get actual predictions using the best estimator from GridSearchCV\n",
        "svm_preds = svm_grid_search.best_estimator_.predict(X_test)\n",
        "knn_preds = knn_grid_search.best_estimator_.predict(X_test)\n",
        "\n",
        "# Evaluate tuned SVM\n",
        "svm_accuracy = accuracy_score(y_test, svm_preds)\n",
        "svm_precision = precision_score(y_test, svm_preds, average='weighted')\n",
        "print(f\"\\nTuned SVM: Accuracy = {svm_accuracy:.2f}, Precision = {svm_precision:.2f}, Best parameters:\", svm_grid_search.best_params_)\n",
        "\n",
        "# Evaluate tuned KNN\n",
        "knn_accuracy = accuracy_score(y_test, knn_preds)\n",
        "knn_precision = precision_score(y_test, knn_preds, average='weighted')\n",
        "print(f\"Tuned KNN: Accuracy = {knn_accuracy:.2f}, Precision = {knn_precision:.2f}, Best parameters:\", knn_grid_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxKuAjBRa8Ft",
        "outputId": "db27fa0f-6ace-4866-8f72-c733ab370df1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance:\n",
            "Linear Regression (SGDClassifier): Accuracy = 0.88, Precision = 0.90\n",
            "SVM (RBF Kernel): Accuracy = 0.78, Precision = 0.79\n",
            "kNN (k=5): Accuracy = 0.69, Precision = 0.69\n",
            "\n",
            "Tuned SVM: Accuracy = 0.91, Precision = 0.92, Best parameters: {'C': 100, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "Tuned KNN: Accuracy = 0.88, Precision = 0.88, Best parameters: {'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'distance'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Approach 1:** PCA-Based Dimensionality Reduction and Feature Selection\n",
        "\n",
        "***Steps:***\n",
        "* Data Cleaning: Removed irrelevant columns and separated features (X) from the target labels (y).\n",
        "\n",
        "* Data Augmentation: Generated 120 synthetic samples by adding Gaussian noise to sampled instances to improve generalization.\n",
        "\n",
        "* Normalization: Applied StandardScaler to standardize the feature values.\n",
        "\n",
        "* Dimensionality Reduction: Used PCA to reduce feature space to 40 principal components, capturing the majority of the variance in the data.\n",
        "\n",
        "* Feature Selection: Applied SelectKBest with ANOVA F-test to select the top 10 most relevant components post-PCA.\n",
        "\n",
        "* Model Training: Evaluated three models – SGDClassifier, SVM (RBF), and kNN (k=5).\n",
        "\n",
        "**Hyperparameter Tuning**: Applied GridSearchCV on SVM and kNN to optimize performance.\n",
        "\n",
        "***Results:***\n",
        "\n",
        "* Best performance: Tuned SVM (Linear kernel) – 91% Accuracy, 92% Precision.\n",
        "\n",
        "* PCA helped improve linear separability, favoring models like SGD and linear SVM.\n",
        "\n",
        "* kNN improved after tuning but remained behind the SVM in this approach.\n",
        "\n"
      ],
      "metadata": {
        "id": "H9o74uDMbGpz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Approach 2:**"
      ],
      "metadata": {
        "id": "0uttPZ7EbIzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and clean data\n",
        "df = pd.read_csv(file_path)\n",
        "df = df.drop(columns=['Unnamed: 0'])\n",
        "\n",
        "X = df.drop(columns=['target'])\n",
        "y = df['target']\n",
        "\n",
        "# --- Topological (Neighbor-based) Pooling ---\n",
        "channel_neighbors = {\n",
        "    1: [], 2: [5, 59, 60], 3: [6, 60], 4: [7, 54], 5: [2], 6: [9, 3], 7: [16, 4],\n",
        "    8: [], 9: [12, 6], 10: [11], 11: [10, 12, 13], 12: [9, 11, 13, 14], 13: [11, 12, 18, 19],\n",
        "    14: [12], 15: [20], 16: [7, 21], 17: [], 18: [13], 19: [13], 20: [15], 21: [16],\n",
        "    22: [26], 23: [24], 24: [23, 25], 25: [24, 26, 27], 26: [22, 25, 27, 28], 27: [26, 30],\n",
        "    28: [26, 31], 29: [32], 30: [32, 27], 31: [28, 33], 32: [32, 29], 33: [31, 36],\n",
        "    34: [36], 35: [37], 36: [33, 34, 38], 37: [35, 39], 38: [36, 40], 39: [37],\n",
        "    40: [38, 42], 41: [51], 42: [40, 46], 43: [44, 47], 44: [45, 43], 45: [44, 46, 48],\n",
        "    46: [42, 45, 48, 49], 47: [43], 48: [45, 46, 52], 49: [46], 50: [53], 51: [54, 41],\n",
        "    52: [48, 55], 53: [50], 54: [4, 51], 55: [52], 56: [59], 57: [60], 58: [59],\n",
        "    59: [2, 56, 58, 60], 60: [2, 3, 57, 59], 61: [], 62: [], 63: [], 64: []\n",
        "}\n",
        "\n",
        "X_pooled = X.copy()\n",
        "for channel, neighbors in channel_neighbors.items():\n",
        "    for band in [\"theta\", \"alpha\", \"beta\", \"gamma\", \"delta\"]:\n",
        "        col = f\"{channel}_{band}\"\n",
        "        neighbor_cols = [f\"{n}_{band}\" for n in neighbors if f\"{n}_{band}\" in X.columns]\n",
        "        if neighbor_cols:\n",
        "            X_pooled[col] = X[neighbor_cols].mean(axis=1)\n",
        "\n",
        "# Data Augmentation: Generate synthetic samples with noise\n",
        "num_synthetic_samples = 120\n",
        "noise_factor = 0.5\n",
        "synthetic_X = X_pooled.sample(n=num_synthetic_samples, replace=True, random_state=42).values\n",
        "synthetic_y = y.sample(n=num_synthetic_samples, replace=True, random_state=42).values\n",
        "synthetic_X += noise_factor * np.random.randn(*synthetic_X.shape)\n",
        "\n",
        "\n",
        "X_augmented = np.vstack((X_pooled.values, synthetic_X))\n",
        "y_augmented = np.hstack((y.values, synthetic_y))\n",
        "\n",
        "# Normalize\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_augmented)\n",
        "\n",
        "# Select top 20 features using ANOVA F-test\n",
        "selector = SelectKBest(score_func=f_classif, k=20)\n",
        "X_selected = selector.fit_transform(X_scaled, y_augmented)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y_augmented, test_size=0.2, random_state=42)\n",
        "\n",
        "# classifiers\n",
        "models = {\n",
        "    \"Linear Regression (SGDClassifier)\": SGDClassifier(loss='log_loss', max_iter=1000),\n",
        "    \"SVM (RBF Kernel)\": SVC(kernel='rbf'),\n",
        "    \"k-Nearest Neighbors (k=5)\": KNeighborsClassifier(n_neighbors=5)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    results[name] = (accuracy, precision)\n",
        "\n",
        "# Output base models\n",
        "print(\"\\nModel Performance:\")\n",
        "for name, (acc, prec) in results.items():\n",
        "    print(f\"{name}: Accuracy = {acc:.2f}, Precision = {prec:.2f}\")\n",
        "\n",
        "# GridSearch Hyperparameter Tuning\n",
        "svm_param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "knn_param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
        "}\n",
        "\n",
        "svm_model = SVC()\n",
        "knn_model = KNeighborsClassifier()\n",
        "\n",
        "svm_grid_search = GridSearchCV(svm_model, svm_param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
        "svm_grid_search.fit(X_train, y_train)\n",
        "\n",
        "knn_grid_search = GridSearchCV(knn_model, knn_param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
        "knn_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Predictions from tuned models\n",
        "svm_best = svm_grid_search.best_estimator_\n",
        "knn_best = knn_grid_search.best_estimator_\n",
        "\n",
        "svm_preds = svm_best.predict(X_test)\n",
        "knn_preds = knn_best.predict(X_test)\n",
        "\n",
        "# Evaluate tuned models\n",
        "svm_accuracy = accuracy_score(y_test, svm_preds)\n",
        "svm_precision = precision_score(y_test, svm_preds, average='weighted')\n",
        "print(f\"\\nTuned SVM: Accuracy = {svm_accuracy:.2f}, Precision = {svm_precision:.2f}, Best parameters:\", svm_grid_search.best_params_)\n",
        "\n",
        "knn_accuracy = accuracy_score(y_test, knn_preds)\n",
        "knn_precision = precision_score(y_test, knn_preds, average='weighted')\n",
        "print(f\"Tuned KNN: Accuracy = {knn_accuracy:.2f}, Precision = {knn_precision:.2f}, Best parameters:\", knn_grid_search.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehB912xpbIGn",
        "outputId": "c26e2eb9-1909-4308-eb1b-b68a4df3d44b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Performance:\n",
            "Linear Regression (SGDClassifier): Accuracy = 0.69, Precision = 0.81\n",
            "SVM (RBF Kernel): Accuracy = 0.78, Precision = 0.85\n",
            "k-Nearest Neighbors (k=5): Accuracy = 0.72, Precision = 0.74\n",
            "\n",
            "Tuned SVM: Accuracy = 0.88, Precision = 0.90, Best parameters: {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Tuned KNN: Accuracy = 0.91, Precision = 0.92, Best parameters: {'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'distance'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Approach 2: Topological Pooling Based on EEG Channel Neighborhoods\n",
        "\n",
        "* Data Cleaning: Same as Approach 1.\n",
        "\n",
        "* Topological Pooling: Leveraged a hand-crafted dictionary of EEG channel neighbors. For each feature (like 2_alpha), it was replaced by the average of its neighbors, encoding spatial relationships among electrodes.\n",
        "\n",
        "* Data Augmentation: Same method as in Approach 1 – added noise to generate synthetic samples.\n",
        "\n",
        "* Normalization: Standardized the data using StandardScaler.\n",
        "\n",
        "* Feature Selection: Used SelectKBest to choose the top 20 features based on ANOVA F-test (no PCA used).\n",
        "\n",
        "* Model Training: Same three models evaluated as in Approach 1.\n",
        "\n",
        "**Hyperparameter Tuning**: Applied GridSearchCV for SVM and kNN.\n",
        "\n",
        "***Results:***\n",
        "\n",
        "* Best performance: Tuned kNN – 91% Accuracy, 92% Precision.\n",
        "\n",
        "* SVM performance improved but was slightly lower than kNN in this setting.\n",
        "\n",
        "* Linear models like SGD did not perform well, likely due to the non-linear nature of pooled data.**bold text**"
      ],
      "metadata": {
        "id": "cACvW-h2bWmg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# General Observations\n",
        "\n",
        "* SVM and kNN models benefit significantly from hyperparameter tuning, confirming their sensitivity to parameters like C, gamma, and n_neighbors.\n",
        "\n",
        "* PCA effectively compresses the high-dimensional EEG data into a smaller, noise-reduced space that retains maximum variance. This transformation helps in making the data more linearly separable, which explains why linear models (like SGD and linear SVM) perform exceptionally well.\n",
        "\n",
        "* With topological processing, kNN performs better than it did with data in approach 1. Since kNN relies on distance metrics in feature space, pooling-based smoothing can reduce local noise and enhance neighborhood consistency, making distance-based classification more stable!"
      ],
      "metadata": {
        "id": "d102PZYobdCK"
      }
    }
  ]
}